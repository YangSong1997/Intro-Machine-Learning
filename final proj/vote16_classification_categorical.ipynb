{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://www.cs.wm.edu/~rml/images/wm_horizontal_single_line_full_color.png\">\n",
    "\n",
    "<h1 style=\"text-align:center;\">CSCI 420: Introduction to Machine Learning final exam</h1>\n",
    "<h1 style=\"text-align:center;\">Problem 3</h1>\n",
    "<h1 style=\"text-align:center;\">Due by 1700 on Tuesday, December 12, 2017</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Name: be sure to write your name here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a classifier for the 2016 presidential election\n",
    "\n",
    "In this problem you will look at county-level data for the 2016 presidential election (\"county\" is used loosely here, since Virginia has independent cities that are also included in the data).\n",
    "\n",
    "The goal is to build a classifier to determine whether a county voted for Clinton or for Trump.\n",
    "\n",
    "The demographic and geographic features for each county are [listed below](#Extract-the-features).\n",
    "\n",
    "An interesting feature of the election was the so-called [Clinton Archipelago](http://www.vividmaps.com/2016/12/trumpland-and-clinton-archipelago.html): Clinton carried relatively few counties compared to Trump (but they were counties with large populations):\n",
    "<pre>\n",
    "Class breakdown:  training set  test set  total\n",
    "       Clinton       330          158       488\n",
    "         Trump      1670          954      2624\n",
    "</pre>\n",
    "\n",
    "The simplest classifier we can build from the training data would be to say all counties vote Trump.  This classifier would be correct for  \n",
    "$$\n",
    "  1 - \\frac{330}{330 + 1670} = 83.5\\%\n",
    "$$\n",
    "of the training cases, and\n",
    "$$\n",
    "1 - \\frac{158}{158 + 954} = 85.8\\%\n",
    "$$\n",
    "of the test cases!  So whatever classifier we build must do substantially better than this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The data\n",
    "\n",
    "The training and test data are in [<code>train_vote16.csv</code>](http://www.cs.wm.edu/~rml/teaching/ml/final/train_vote16.csv) and [<code>test_vote16.csv</code>](http://www.cs.wm.edu/~rml/teaching/ml/final/test_vote16.csv), respectively.  These are CSV files.\n",
    "\n",
    "Column 0 is the class label:\n",
    "<pre>\n",
    "0: won by Clinton\n",
    "1: won by Trump\n",
    "</pre>\n",
    "\n",
    "The next two columns are the actual number of votes from 2016.  We won't use those &ndash; that would be cheating!\n",
    "\n",
    "The next three columns are:\n",
    "<pre>\n",
    "state_abbr:  the state's abbreviation\n",
    "county_name: the name of the county or city\n",
    "state_fips:  the Federal Information Processing Standards code for the state\n",
    "FIPS:        the Federal Information Processing Standards code for the county or city\n",
    "</pre>\n",
    "\n",
    "These are followed by information about the 2012 election, including the proportion voting for Obama and Romney as well as the vote totals themselves:\n",
    "<pre>\n",
    "total_votes_2012: total number of votes cast in the 2012 election\n",
    "votes_dem_2012:   number of votes cast for the Democratic candidate in 2012\n",
    "votes_rep_2012:   number of votes cast for the Republican candidate in 2012\n",
    "Obama:            percentage voting for Obama in 2012\n",
    "Romney:           percentage voting for Romney in 2012\n",
    "</pre>\n",
    "\n",
    "The remaining columns are demographic data about the county or city:\n",
    "<pre>\n",
    "PST045214: Population, 2014 estimate\n",
    "PST040210: Population, 2010 (April 1) estimates base\n",
    "PST120214: Population, percent change - April 1, 2010 to July 1, 2014\n",
    "POP010210: Population, 2010\n",
    "AGE135214: Persons under 5 years, percent, 2014\n",
    "AGE295214: Persons under 18 years, percent, 2014\n",
    "AGE775214: Persons 65 years and over, percent, 2014\n",
    "SEX255214: Female persons, percent, 2014\n",
    "RHI125214: White alone, percent, 2014\n",
    "RHI225214: Black or African American alone, percent, 2014\n",
    "RHI325214: American Indian and Alaska Native alone, percent, 2014\n",
    "RHI425214: Asian alone, percent, 2014\n",
    "RHI525214: Native Hawaiian and Other Pacific Islander alone, percent, 2014\n",
    "RHI625214: Two or More Races, percent, 2014\n",
    "RHI725214: Hispanic or Latino, percent, 2014\n",
    "RHI825214: White alone, not Hispanic or Latino, percent, 2014\n",
    "POP715213: Living in same house 1 year & over, percent, 2009-2013\n",
    "POP645213: Foreign born persons, percent, 2009-2013\n",
    "POP815213: Language other than English spoken at home, pct age 5+, 2009-2013\n",
    "EDU635213: High school graduate or higher, percent of persons age 25+, 2009-2013\n",
    "EDU685213: Bachelor's degree or higher, percent of persons age 25+, 2009-2013\n",
    "VET605213: Veterans, 2009-2013\n",
    "LFE305213: Mean travel time to work (minutes), workers age 16+, 2009-2013\n",
    "HSG010214: Housing units, 2014\n",
    "HSG445213: Homeownership rate, 2009-2013\n",
    "HSG096213: Housing units in multi-unit structures, percent, 2009-2013\n",
    "HSG495213: Median value of owner-occupied housing units, 2009-2013\n",
    "HSD410213: Households, 2009-2013\n",
    "HSD310213: Persons per household, 2009-2013\n",
    "INC910213: Per capita money income in past 12 months (2013 dollars), 2009-2013\n",
    "INC110213: Median household income, 2009-2013\n",
    "PVY020213: Persons below poverty level, percent, 2009-2013\n",
    "BZA010213: Private nonfarm establishments, 2013\n",
    "BZA110213: Private nonfarm employment,  2013\n",
    "BZA115213: Private nonfarm employment, percent change, 2012-2013\n",
    "NES010213: Nonemployer establishments, 2013\n",
    "SBO001207: Total number of firms, 2007\n",
    "SBO315207: Black-owned firms, percent, 2007\n",
    "SBO115207: American Indian- and Alaska Native-owned firms, percent, 2007\n",
    "SBO215207: Asian-owned firms, percent, 2007\n",
    "SBO515207: Native Hawaiian- and Other Pacific Islander-owned firms, percent, 2007\n",
    "SBO415207: Hispanic-owned firms, percent, 2007\n",
    "SBO015207: Women-owned firms, percent, 2007\n",
    "MAN450207: Manufacturers shipments, 2007 ($1,000)\n",
    "WTN220207: Merchant wholesaler sales, 2007 ($1,000)\n",
    "RTN130207: Retail sales, 2007 ($1,000)\n",
    "RTN131207: Retail sales per capita, 2007\n",
    "AFN120207: Accommodation and food services sales, 2007 ($1,000)\n",
    "BPS030214: Building permits, 2014\n",
    "LND110210: Land area in square miles, 2010\n",
    "POP060210: Population per square mile, 2010\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# To Do\n",
    "\n",
    "* Build a classifier that predicts how a county votes with at least 97% overall accuracy.  It isn't too difficult to obtain 98% overall accuracy, and at least 95% accuracy for each candidate.  More accurate is better for this problem.\n",
    "* Populate this Jupyter notebook with the code needed to create, train, and run your CNN.\n",
    "    * As part of your model evaluation, your notebook should compute and print the confusion matrix and f1-scores.\n",
    "* You should build your classifier and any preprocessing as a scikit-learn <code>Pipeline</code>.\n",
    "* You should save your classification pipeline to the file <code>vote16_clf.pkl</code> using <code>sklearn.externals.joblib</code> (see below).\n",
    "* If you use a grid search or random search for hyperparameter tuning, you should indicate this in the write-up below, and submit the hyperparameters used in the submitted solution (you can just specify them in calls to the classifier's constructor).\n",
    "* If you try a classifier and it does not work to your liking, you should indicate this.  You can leave the code in the notebook, commented out, so I can see what you tried.\n",
    "\n",
    "* You can choose from any of the classifiers we studied, including\n",
    " - [k nearest neighbors](http://scikit-learn.org/stable/modules/neighbors.html),\n",
    " - [support vector machines / kernel machines](http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html),\n",
    " - [decision trees](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier),\n",
    " - [logistic regression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html),\n",
    " - [neural networks](http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier) (you will need scikit-learn 0.18 for this; use <code>conda update scikit-learn</code>),\n",
    " - ensembles of the preceding (i.e., [random forests](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) and [AdaBoosted collections of weak learners](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html)),\n",
    " - [neural networks](http://scikit-learn.org/stable/modules/neural_networks_supervised.html)\n",
    " \n",
    "## Note\n",
    "\n",
    "In order to build a pipeline you will need to implement your own first step of the pipeline in order to perform feature selection and any necessary feature encoding.  You can do so by creating your own class with a <code>fit()</code> and <code>transform()</code> method.  \n",
    "\n",
    "The calling sequences and return sequences of these two methods should be the same as those of the StandardScaler [<code>fit()</code>](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler.fit) and [<code>transform()</code>](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler.transform).\n",
    "\n",
    "For example, <code>fit()</code> might not do anything while <code>transform()</code> will return a subset of the variables as a numpy array.\n",
    "\n",
    "For full credit your pipeline should encapsulate all of your preprocessing steps.  If you cannot figure out how to make this work, you can enter your preprocessing steps below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions to answer\n",
    "\n",
    "1. What classifiers did you try?\n",
    "2. What tuning did you do?\n",
    "3. How did the classifiers perform?\n",
    "4. If you end up with a decision tree, explain how the tree makes its decisions.  For other classifiers, try to give some insight into why it works.\n",
    "5. What is cross-validation, and how can it be used in constructing classifiers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What to submit\n",
    "\n",
    "1. This Jupyter notebook, filled out with code that when run will produce a working classifer with all necessary preprocessing.\n",
    "    * You should use your final hyperparameter values in the call to the classifier's constructor.\n",
    "2. If you get the pipeline working, the resulting <code>.pkl</code> file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your code follows\n",
    "\n",
    "You are free to change the section titles, add sections, &amp;c."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading data...done!\n",
      "[[ 19073.   4804.   2369. ...,      0.      0.      0.]\n",
      " [ 13119.   7757.   1499. ...,      0.      0.      0.]\n",
      " [ 37133.  50353.  18115. ...,      0.      0.      0.]\n",
      " ..., \n",
      " [ 13193.   4781.   3211. ...,      0.      0.      0.]\n",
      " [ 46039.   2171.    941. ...,      0.      0.      0.]\n",
      " [ 13269.   3537.   1571. ...,      0.      0.      0.]]\n",
      "[[ 18095.  52340.  24404. ...,      0.      0.      0.]\n",
      " [ 22121.  12772.   5692. ...,      0.      0.      0.]\n",
      " [ 27055.  10422.   5281. ...,      0.      0.      0.]\n",
      " ..., \n",
      " [ 22095.  21122.  13178. ...,      0.      0.      0.]\n",
      " [ 27021.  16080.   6858. ...,      0.      0.      0.]\n",
      " [ 20005.   6499.   2486. ...,      0.      0.      0.]]\n",
      "(2000, 1954)\n",
      "(1112, 1954)\n",
      "[ 1.  1.  1. ...,  0.  1.  1.]\n",
      "[ 1.  1.  1. ...,  0.  1.  1.]\n",
      "(2000,)\n",
      "(1112,)\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy  as np\n",
    "\n",
    "print('reading data...', end='')\n",
    "df_train = pd.read_csv('train_vote16.csv')\n",
    "df_test  = pd.read_csv('test_vote16.csv')\n",
    "print('done!')\n",
    "\n",
    "x_train = df_train.iloc[:,3:]\n",
    "x_test  = df_test.iloc[:,3:]\n",
    "\n",
    "y_train = df_train.iloc[:,0]\n",
    "y_test  = df_test.iloc[:,0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#print(type(x_train))\n",
    "#print(y_train)\n",
    "#print(y_test)\n",
    "\n",
    "\n",
    "#print(x_train)\n",
    "#print(x_test)\n",
    "frames = [x_train,x_test]\n",
    "result = pd.concat(frames)\n",
    "result_with_dummies = pd.get_dummies(result,columns=[\"state_abbr\",\"county_name\"],drop_first=False)\n",
    "#print(result)\n",
    "#print(result_with_dummies)\n",
    "#print(list(result_with_dummies))\n",
    "n = 2000\n",
    "x_train_dum = result_with_dummies[:n]\n",
    "x_test_dum = result_with_dummies[n:]\n",
    "#print(x_train_dum)\n",
    "#print(x_test_dum)\n",
    "\n",
    "x_train_new = x_train_dum.as_matrix(columns=None)\n",
    "x_test_new = x_test_dum.as_matrix(columns=None)\n",
    "\n",
    "x_train_new = np.array(list(x_train_new))\n",
    "x_test_new = np.array(list(x_test_new))\n",
    "\n",
    "\n",
    "print(x_train_new)\n",
    "print(x_test_new)\n",
    "print(x_train_new.shape)\n",
    "print(x_test_new.shape)\n",
    "\n",
    "\n",
    "\n",
    "y_train_new = y_train.as_matrix(columns=None)\n",
    "y_test_new = y_test.as_matrix(columns=None)\n",
    "\n",
    "\n",
    "y_train_new = np.array(list(y_train_new))\n",
    "y_test_new = np.array(list(y_test_new))\n",
    "\n",
    "print(y_train_new)\n",
    "print(y_test_new)\n",
    "print(y_train_new.shape)\n",
    "print(y_test_new.shape)\n",
    "print(y_test_new.ndim)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify the classification pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Train the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "def compute_metrics (classifier, X_test, y_test):\n",
    "    \"\"\"\n",
    "    This function computes and prints various performance measures for a classifier.\n",
    "    \"\"\"\n",
    "    # Use the classifier to make predictions for the test set.\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    # Choose the class with the highest estimated probability.\n",
    "    #y_pred = np.argmax(y_pred, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "    # Compute the confusion matrix.\n",
    "    cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "    print('Confusion matrix, without normalization')\n",
    "    print(cm, '\\n')\n",
    "\n",
    "    # Normalize the confusion matrix by row (i.e by the number of samples in each class).\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    np.set_printoptions(precision=3, linewidth=132)\n",
    "    print('Normalized confusion matrix')\n",
    "    print(cm_normalized, '\\n')\n",
    "\n",
    "    # The confusion matrix as percentages.\n",
    "    cm_percentage = 100 * cm_normalized\n",
    "    print('Confusion matrix as percentages')\n",
    "    print(np.array2string(cm_percentage, formatter={'float_kind':lambda x: \"%6.2f\" % x}), '\\n')\n",
    "    \n",
    "    # Precision, recall, and f-score.\n",
    "    print(metrics.classification_report(y_test, y_pred, digits=3))\n",
    "\n",
    "    return cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.973021582734\n",
      "Confusion matrix, without normalization\n",
      "[[  1 157]\n",
      " [  2 952]] \n",
      "\n",
      "Normalized confusion matrix\n",
      "[[ 0.006  0.994]\n",
      " [ 0.002  0.998]] \n",
      "\n",
      "Confusion matrix as percentages\n",
      "[[  0.63  99.37]\n",
      " [  0.21  99.79]] \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0      0.333     0.006     0.012       158\n",
      "        1.0      0.858     0.998     0.923       954\n",
      "\n",
      "avg / total      0.784     0.857     0.794      1112\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  1, 157],\n",
       "       [  2, 952]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_fit = scaler.fit_transform(x_train_new)\n",
    "X_test_fit = scaler.fit_transform(x_test_new)\n",
    "\n",
    "#svm = SVC(kernel='rbf', C=100.0, gamma=0.01,random_state=0)\n",
    "#Svc = svm.fit(X_train_fit,y_train_new)\n",
    "# 0.85701438848920863 accuracy\n",
    "\n",
    "#lr = LogisticRegression(C=100.0, random_state=0)\n",
    "#log_reg = lr.fit(X_train_fit, y_train_new)\n",
    "# 0.91276978417266186\n",
    "\n",
    "tree = DecisionTreeClassifier(criterion='entropy', max_depth=6, random_state=0)\n",
    "dec_tree = tree.fit(X_train_fit, y_train_new)\n",
    "# 0.97122302158273377 with depth 7\n",
    "# 0.9730215827338129  with depth 6\n",
    "# 0.97212230215827333 with depth 5\n",
    "\n",
    "#knn = KNeighborsClassifier(n_neighbors=5, p=2, metric='minkowski')\n",
    "#KNN = knn.fit(X_train_fit, y_train_new)\n",
    "# 0.89928057553956831\n",
    "\n",
    "#compute_metrics(Svc, X_test_fit, y_test_new)\n",
    "y_pred = dec_tree.predict(X_test_fit)\n",
    "print(metrics.accuracy_score(y_test_new,y_pred))\n",
    "\n",
    "#print(confusion_matrix(y_test_new, y_pred))\n",
    "\n",
    "compute_metrics(Svc, X_test_fit, y_test_new)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1.  1. ...,  0.  1.  1.]\n",
      "(1112,)\n",
      "(1112,)\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)\n",
    "print(y_pred.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Save the classification pipeline\n",
    "\n",
    "&hellip;assuming it is named <code>clf</code>&hellip;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "print('Saving the classifier...')\n",
    "joblib.dump(clf, 'vote16_clf.pkl')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
